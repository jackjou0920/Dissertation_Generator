{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_dot(sentence):\n",
    "    word_punct_tokenizer = WordPunctTokenizer()\n",
    "    tokens = word_punct_tokenizer.tokenize(sentence)\n",
    "#     print(tokens)\n",
    "    for word in tokens:\n",
    "        if re.search('\\.\\.(\\.)+', word):\n",
    "            return True\n",
    "        if re.search('\\-\\-(\\-)+', word):\n",
    "            return True\n",
    "        if re.search('\\_\\_(\\_)+', word):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_length(sentence):\n",
    "    word_punct_tokenizer = WordPunctTokenizer()\n",
    "    tokens = word_punct_tokenizer.tokenize(sentence)\n",
    "    \n",
    "    if (len(tokens) > 10):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def short_length(sentence):\n",
    "    word_punct_tokenizer = WordPunctTokenizer()\n",
    "    tokens = word_punct_tokenizer.tokenize(sentence)\n",
    "    if (len(tokens) < 1000):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain(sentence, reference):\n",
    "    if (over_dot(sentence)):\n",
    "        return False\n",
    "    \n",
    "    word_punct_tokenizer = WordPunctTokenizer()\n",
    "    tokens = word_punct_tokenizer.tokenize(sentence)\n",
    "    for word in tokens:\n",
    "        if (word not in reference):\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(path, text):\n",
    "    with open(path, 'w', encoding='utf-8') as fp:\n",
    "        fp.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(text):\n",
    "    text = text.lower()\n",
    "    lines = text.splitlines()\n",
    "    \n",
    "    lr_start = ['chapter', 'chapter2', '2', 'ii', '.', ':', '–', '-', '|', '\\t', 'literature', 'reviews', 'review', \n",
    "                'background', 'previous', 'systems', 'related', 'studies', 'of', 'work', 'technology', 'research', \n",
    "                'survey', 'research', 'conceptual', 'project', 'concepts', 'and', 'technical', 'knowledge', 'analytical']\n",
    "    has_ch2 = False\n",
    "    has_ch3 = False\n",
    "    is_lr = False\n",
    "    num_line = 0\n",
    "    literature = \"\"\n",
    "    for line in lines:\n",
    "        if (is_lr):\n",
    "            num_line += 1\n",
    "            literature += line + '\\n'\n",
    "#         print(line)\n",
    "        if ('chapter 2' in line) or ('chapter2' in line) or ('chapter ii' in line):\n",
    "            if (contain(line, lr_start)):\n",
    "                print(line)\n",
    "                is_lr = True\n",
    "                has_ch2 = True   \n",
    "        elif ('chapter 3' in line) or ('chapter\\t3' in line) or ('chapter3' in line) or ('chapter iii' in line):\n",
    "#             print(line)\n",
    "            if (over_dot(line) == False) and (over_length(line) == False):\n",
    "                print(line)\n",
    "                if (num_line <= 50) or short_length(literature):\n",
    "                    literature = \"\"\n",
    "                    num_line = 0\n",
    "                    has_ch2 = False\n",
    "                    has_ch3 = False\n",
    "                else:\n",
    "                    literature = literature.replace(line+'\\n', \"\")\n",
    "                    if (has_ch2):\n",
    "                        has_ch3 = True\n",
    "                    break\n",
    "                    \n",
    "                \n",
    "                \n",
    "                is_lr = False\n",
    "#     print('literature:')\n",
    "#     print(literature)\n",
    "    return has_ch2, has_ch3, literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract2(text):\n",
    "    text = text.lower()\n",
    "    lines = text.splitlines()\n",
    "    lr_start = ['chapter', 'chapter2', '2', 'ii', '.', ':', '–', '-', '|', '\\t', 'literature', 'reviews', 'review', \n",
    "                'background', 'previous', 'systems', 'related', 'studies', 'of', 'work', 'technology', 'research', \n",
    "                'survey', 'research', 'conceptual', 'project', 'concepts', 'and', 'technical', 'knowledge', 'analytical']\n",
    "    has_ch2 = False\n",
    "    has_ch3 = False\n",
    "    is_lr = False\n",
    "    num_line = 0\n",
    "    literature = \"\"\n",
    "    for line in lines:\n",
    "        if (is_lr):\n",
    "            num_line += 1\n",
    "            literature += line + '\\n'\n",
    "#         print(line)\n",
    "        if ('literature review' in line) or ('background review' in line) or ('literature survey' in line):\n",
    "            if (contain(line, lr_start)):\n",
    "#                 print(line)\n",
    "                is_lr = True\n",
    "                has_ch2 = True\n",
    "        elif ('requirements and analysis' in line) or ('requirement and analysis' in line):\n",
    "#             print(line)\n",
    "            if (over_dot(line) == False) and (over_length(line) == False):\n",
    "                print(line)\n",
    "                if (num_line <= 50) or short_length(literature):\n",
    "                    literature = \"\"\n",
    "                    num_line = 0\n",
    "                    has_ch2 = False\n",
    "                    has_ch3 = False\n",
    "                else:\n",
    "                    literature = literature.replace(line+'\\n', \"\")\n",
    "                    if (has_ch2):\n",
    "                        has_ch3 = True\n",
    "                    break\n",
    "                is_lr = False\n",
    "#     print('literature:')\n",
    "#     print(literature)\n",
    "    return has_ch2, has_ch3, literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lr():\n",
    "    lr_list = []\n",
    "#     dirPath = './ug_dataset/literature_review/'\n",
    "    dirPath = './ug_dataset/literature_review/'\n",
    "    files = [f for f in os.listdir(dirPath) if os.path.isfile(os.path.join(dirPath, f))]\n",
    "    files = sorted(files)\n",
    "    for fname in files:\n",
    "        if ('txt' not in fname):\n",
    "            continue\n",
    "        lr_list.append(fname)\n",
    "    return lr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "722\n"
     ]
    }
   ],
   "source": [
    "lr_list = load_lr()\n",
    "print(len(lr_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirPath = './ug_dataset/tmp/'\n",
    "# dirPath = './msc_dataset/tmp/'\n",
    "files = [f for f in os.listdir(dirPath) if os.path.isfile(os.path.join(dirPath, f))]\n",
    "files = sorted(files)\n",
    "count = 0\n",
    "for fname in files:\n",
    "    if ('txt' not in fname):\n",
    "        continue\n",
    "    if (fname in lr_list):\n",
    "#         os.remove(dirPath+fname)\n",
    "        continue\n",
    "    print(fname)\n",
    "    count += 1\n",
    "    \n",
    "    with open(dirPath+fname, \"r\", encoding=\"utf-8\") as fp:\n",
    "        text = fp.read()\n",
    "#         has_ch2, has_ch3, literature = extract(text)\n",
    "        has_ch2, has_ch3, literature = extract2(text)\n",
    "        if (has_ch2 == True) and (has_ch3 == True) and (literature != \"\"):\n",
    "            save_file('./ug_dataset/lr/'+fname, literature)\n",
    "        else:\n",
    "            print('No save')\n",
    "        print()\n",
    "#     if (count == 1):\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
