{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time, MySQLdb, os\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.alert import Alert\n",
    "from selenium.webdriver.support.ui import WebDriverWait as wait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Firefox()\n",
    "# driver.get(url + 'index.html')\n",
    "\n",
    "# wait(driver, 5).until(EC.alert_is_present())\n",
    "\n",
    "# # Switch the control to the Alert window\n",
    "# alert = driver.switch_to_alert()\n",
    "# alert.send_keys(\"acp18dj\" + Keys.TAB + \"jack282505\")\n",
    "# alert.accept()\n",
    "# time.sleep(5)\n",
    "# html_doc = driver.page_source\n",
    "# soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "# driver.close()\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_headers = {\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Accept-Language': 'en,zh-TW;q=0.9,zh;q=0.8',\n",
    "    'Authorization': 'Basic YWNwMThkajpqYWNrMjgyNTA1',\n",
    "    'Cache-Control': 'no-cache',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Cookie': '__utma=233425244.1247113454.1521441727.1521441727.1521441727.1; _ga_global=GA1.3.1247113454.1521441727',\n",
    "    'Host': 'www.dcs.shef.ac.uk',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.87 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    requestsession = requests.Session()\n",
    "    page = requestsession.get(url, headers=login_headers)\n",
    "    page.encoding='utf-8'\n",
    "    soup = BeautifulSoup(page.content, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_page(year):\n",
    "#     url = 'https://www.dcs.shef.ac.uk/intranet/archive/campus/2017_2018/projects/msc/'\n",
    "#     url = 'http://www.dcs.shef.ac.uk/intranet/archive/public/' + year + '/projects/msc/'\n",
    "    url = 'http://www.dcs.shef.ac.uk/intranet/archive/public/' + year + '/projects/ug/'\n",
    "    main_soup = get_page(url)\n",
    "    tables = main_soup.findAll('table')\n",
    "    tab = tables[2]\n",
    "    return url, tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_abst(url):\n",
    "    abstract = \"\"\n",
    "    abst_soup = get_page(url)\n",
    "    abst_soup.encoding='utf-8'\n",
    "    body = abst_soup.find(id='bodyContainer')\n",
    "    for content in body.findAll('p'):\n",
    "        abstract += content.getText()\n",
    "    return abstract.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf(url, file):\n",
    "    print(\"start download:\", file)\n",
    "    response = requests.get(url, headers=login_headers, stream=\"TRUE\")\n",
    "    print(response)\n",
    "    with open('./Dissertation/previous/'+file, 'wb') as file:\n",
    "        for data in response.iter_content():\n",
    "            file.write(data)\n",
    "    print(\"download finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_db(rows):\n",
    "    db = MySQLdb.connect(host=\"143.167.8.208\", user=\"root\", passwd=\"jack\", db=\"dissertation\")\n",
    "    cursor = db.cursor()\n",
    "\n",
    "    sql = \"INSERT INTO Test(filename,topic,abstract) VALUES(%s,%s,%s)\"\n",
    "    try:\n",
    "        cursor.executemany(sql, rows)\n",
    "        db.commit()\n",
    "    except MySQLdb.Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(path, text):\n",
    "    with open(path, 'w') as out_file:\n",
    "        out_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping(year):\n",
    "    url, tab = load_page(year)\n",
    "\n",
    "    count = 0\n",
    "    num = 0\n",
    "    topic_path = './msc_dataset/topic/'\n",
    "    abstract_path = './msc_dataset/abstract/'\n",
    "    tab = tab.findAll('table')[0]\n",
    "    for tr in tab.findAll('tr'):\n",
    "#     for tr in tab.tbody.findAll('tr'):\n",
    "        \n",
    "        dis_none = False\n",
    "        idx = 0\n",
    "        count += 1\n",
    "        if(count == 1):\n",
    "            continue\n",
    "\n",
    "        filename = \"\"\n",
    "        topic = \"\"\n",
    "        abstract = \"\"\n",
    "        c = 0\n",
    "        for td in tr.findAll('td'):\n",
    "            c += 1\n",
    "        for td in tr.findAll('td'):\n",
    "            idx += 1\n",
    "            if (idx == 1):\n",
    "                print(td.getText().strip())\n",
    "            if (idx == 2):\n",
    "                topic = td.getText().strip()\n",
    "            if (idx == 3):\n",
    "                abt = td.find_all('a')\n",
    "                if (len(abt) == 0):\n",
    "                    abstract = \"\"\n",
    "                else:\n",
    "                    abst_url = url + abt[0]['href']\n",
    "                    abstract = parse_abst(abst_url)\n",
    "                    \n",
    "            if (idx == 4):\n",
    "                dis = td.find_all('a')\n",
    "                if (len(dis) == 0):\n",
    "                    dis_none = True\n",
    "                else:\n",
    "                    is_none = False\n",
    "                    dis_url = dis[0]['href']\n",
    "#                       file = dis_url.replace('https://www.dcs.shef.ac.uk/intranet/archive/campus/'+year+'/projects/msc/', \"\")\n",
    "                    file = dis_url.replace('https://www.dcs.shef.ac.uk/intranet/archive/campus/'+year+'/projects/ug/', \"\")\n",
    "                    filename = file.replace(\".pdf\", \"\")\n",
    "                    print(filename)\n",
    "                    # download_pdf(dis_url, file)\n",
    "        if (dis_none == False):\n",
    "            num += 1\n",
    "            write_file(topic_path+filename+'.txt', topic)\n",
    "            write_file(abstract_path+filename+'.txt', abstract)\n",
    "    print(num)\n",
    "    \n",
    "#     if (is_none):\n",
    "#         data = (filename, topic, abstract)\n",
    "#     else:\n",
    "#         data = (filename, topic, abst)\n",
    "#     rows.append(data)\n",
    "#     if (count == 3):\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filename():\n",
    "    dirPath = './msc_dataset/topic/'\n",
    "    files = [f for f in os.listdir(dirPath) if os.path.isfile(os.path.join(dirPath, f))]\n",
    "    files = sorted(files)\n",
    "    for fname in files:\n",
    "        print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_db(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['2017_2018', '2016_2017', '2015_2016', '2014_2015', '2013_2014', '2012_2013', '2011_2012', '2010_2011',\n",
    "        '2009_2010', '2008_2009', '2007_2008', '2006_2007', '2005_2006', '2004_2003', '2003_2004', '2002_2003',\n",
    "        '2001_2002', '2000_2001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './msc_dataset/topic/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6852c7451c55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-cfa1bdc86534>\u001b[0m in \u001b[0;36mload_filename\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdirPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./msc_dataset/topic/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirPath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './msc_dataset/topic/'"
     ]
    }
   ],
   "source": [
    "load_filename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for y in years:\n",
    "    print(y)\n",
    "    scraping(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
